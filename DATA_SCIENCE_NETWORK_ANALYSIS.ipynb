{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing the Necessary modules**"
      ],
      "metadata": {
        "id": "ZFVG6VRk0tK-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKzVu3-aGcv3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd                                     # Importing pandas library for reading the dataset file\n",
        "import numpy as np                                      # Importing the numpy module for\n",
        "import sklearn                                          # Importing the sklearn module for model selction\n",
        "import seaborn as sns                                   # Importing the seaborn module for data visualization\n",
        "import matplotlib.pyplot as plt                         # importing the matplotlib module for graph plotting\n",
        "import networkx as nx                                   # importing the networkx module for graph or node plotting\n",
        "from itertools import combinations                      # importing the combinations module from itertools for node community\n",
        "import random                                           # Importing Random module for randomization\n",
        "from multiprocessing import Pool\n",
        "from networkx.algorithms.community import greedy_modularity_communities\n",
        "from community import community_louvain                 # Community detection using Louvain algorithm\n",
        "\n",
        "\n",
        "pd.set_option(\"display.max_columns\", None)              # Method to set max display columns and rows of the dataset.\n",
        "pd.set_option(\"display.max_rows\", 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the social network dataset file from open source**"
      ],
      "metadata": {
        "id": "FE9i_w2j083K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/SocialMediaUsersDataset.csv')      # Load the data into a pandas DataFrame and reading the file\n",
        "data.head()"
      ],
      "metadata": {
        "id": "99VH9b-tX6FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape                # Checking the shape of dataset"
      ],
      "metadata": {
        "id": "JinxcLKFbA8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Observations**\n",
        "\n",
        "Since our dataset has huge records or nodes which will take very much long time to execute and create the anlysis. So as per our need we required 1k to 1.5k nodes atleast. so we sampled 2k nodes from our dataset to make our analysis smooth, so below we did it."
      ],
      "metadata": {
        "id": "_AJe1Jsp1qty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Network Construction Process**\n",
        "\n"
      ],
      "metadata": {
        "id": "H5afXqGB25lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.1 Making nodes upto 2k**"
      ],
      "metadata": {
        "id": "hfAyITwzD9Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.sample(n=2000, random_state=42)    # Now df contains a random sample of 2000 Nodes or records\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Xas4QScVbBFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape                # Checking the shape of new 2k nodes records dataset"
      ],
      "metadata": {
        "id": "jZOsfmeTeQLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.2 Determing Nodes and Edges Relationship**"
      ],
      "metadata": {
        "id": "Uc65qC6CEVLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()                                                             # Create an empty graph\n",
        "for index, row in df.iterrows():\n",
        "    G.add_node(row['UserID'], Gender=row['Gender'],\n",
        "    DOB=row['DOB'], Interests=row['Interests'], City=row['City'],\n",
        "    Country=row['Country'])                                                 # Add nodes with attributes\n",
        "for (user1, data1), (user2, data2) in combinations(G.nodes(data=True), 2):  # Add edges based on shared interests (simplified)\n",
        "    interests1 = set(data1['Interests'].split(', '))\n",
        "    interests2 = set(data2['Interests'].split(', '))\n",
        "    if interests1 & interests2:\n",
        "        G.add_edge(user1, user2, weight=len(interests1 & interests2))\n",
        "print(\"Summary of Network:\")                                                 # Summarize key information\n",
        "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
        "print(f\"Number of edges: {G.number_of_edges()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OgexrDA5DMhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Observations**\n",
        "\n",
        "So total 2k nodes in our sample network and total 528850 edges connetced with nodes. It shows that definitely each nodes as connected with multiple nodes to eachother"
      ],
      "metadata": {
        "id": "1NgIKeFPGLAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **1.3 Additional adding Edge weights**"
      ],
      "metadata": {
        "id": "kFXJ6Zu8FGPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_attributes = nx.get_node_attributes(G, 'Gender')                          # Additional progress: Collecting node attributes and edge weights\n",
        "edge_weights = nx.get_edge_attributes(G, 'weight')\n",
        "if edge_weights:                                                               # Calculate average edge weight\n",
        "    avg_edge_weight = sum(edge_weights.values()) / len(edge_weights)\n",
        "    print(f\"Average edge weight: {avg_edge_weight:.2f}\")\n",
        "plt.figure(figsize=(10, 7))                                                      # Basic visualization\n",
        "pos = nx.spring_layout(G, seed=42)                                             # Seed for reproducibility\n",
        "nx.draw(G, pos, node_size=20, edge_color='lightgreen', with_labels=False)\n",
        "plt.title('Network Visualization')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bVxT0jvRFE-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Network Analysis Process**\n",
        "\n"
      ],
      "metadata": {
        "id": "NUUWTApoG7QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.1 Degree distribution analysis**"
      ],
      "metadata": {
        "id": "8jZsN4PDHTUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "degrees = [G.degree(n) for n in G.nodes()]                      # Degree Distribution\n",
        "plt.hist(degrees)\n",
        "plt.title('Degree Distribution')\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Number of Nodes')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "e5Uv5wgCFFBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)              # Degree distribution plot\n",
        "degree_count = pd.Series(degree_sequence).value_counts().sort_index()\n",
        "plt.figure(figsize=(12, 7))\n",
        "plt.bar(degree_count.index, degree_count.values)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Number of Nodes')\n",
        "plt.title('Node Degree Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P8n2-HbDFFD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.2 Connected components analysis**"
      ],
      "metadata": {
        "id": "OJxTRcTfIcdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "connected_components = [len(c) for c in sorted(nx.connected_components(G), key=len, reverse=True)]     # Connected Components Analysis\n",
        "print(\"Number of Connected Components:\", len(connected_components))\n"
      ],
      "metadata": {
        "id": "VUkGq4OiFFGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.3 Path analysis**"
      ],
      "metadata": {
        "id": "SuG0O3_PI8fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodes = list(G.nodes())                                                  # Path Analysis - Example: shortest path between two randomly chosen nodes\n",
        "source, target = random.sample(nodes, 2)\n",
        "try:\n",
        "    shortest_path = nx.shortest_path(G, source=source, target=target)\n",
        "    print(f\"Shortest path from {source} to {target}: {shortest_path}\")\n",
        "except nx.NetworkXNoPath:\n",
        "    print(f\"No path exists between {source} and {target}.\")\n"
      ],
      "metadata": {
        "id": "maz42RaFFFJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_node = list(G.nodes())[0]                                                 # Path Analysis Visualization\n",
        "target_node = list(G.nodes())[1]\n",
        "shortest_path = nx.shortest_path(G, source=source_node, target=target_node)      # Find shortest path and visualize it\n",
        "plt.figure(figsize=(12, 7))                                                        # Highlight the shortest path in the network visualization\n",
        "nx.draw(G, pos, node_size=20, edge_color='lightgreen', with_labels=False)\n",
        "nx.draw_networkx_nodes(G, pos, nodelist=shortest_path, node_color='darkblue', node_size=20)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=[(shortest_path[i], shortest_path[i+1]) for i in range(len(shortest_path)-1)],\n",
        "                       edge_color='red', width=2)\n",
        "plt.title('Shortest Path Visualization')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UIDVdqhRDfnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.4 Clustering Coefficient and Density analysis**"
      ],
      "metadata": {
        "id": "D9x8_MXSK6zZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_clustering = nx.average_clustering(G)                         # Clustering Coefficient\n",
        "print(f\"Average clustering coefficient: {avg_clustering}\")"
      ],
      "metadata": {
        "id": "Or2VP_6JDfp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "density = nx.density(G)                                           # Network Density\n",
        "print(f\"Network density: {density}\")"
      ],
      "metadata": {
        "id": "mnGLBwG-Dfsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2.5 Centrality analysis**\n",
        "Statistics compared with those of\n",
        "\n",
        "(i) ER,\n",
        "\n",
        "(ii) BA, and\n",
        "\n",
        "(iii) WS\n",
        "\n",
        "graphs having a similar number of nodes and edges**"
      ],
      "metadata": {
        "id": "KPiFAGA9Lnpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "degree_centrality = nx.degree_centrality(G)                                         # Degree Centrality\n",
        "top_10 = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10] # Get the top 5 nodes by degree centrality\n",
        "print(\"Top 10 nodes by degree centrality:\", top_10)"
      ],
      "metadata": {
        "id": "wPy_HTAsDfvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_centrality(centrality):                                         # Print average centrality measures\n",
        "    return np.mean(list(centrality.values()))\n"
      ],
      "metadata": {
        "id": "GhrtHOhr_vVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degree_centrality = nx.degree_centrality(G)                                 # Calculate centrality measures for the original graph\n",
        "closeness_centrality = nx.closeness_centrality(G)\n"
      ],
      "metadata": {
        "id": "OIADw3yPZmDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Graph:\")                                                        # Print average centrality measures for the original graph\n",
        "print(\"Average Degree Centrality:\", average_centrality(degree_centrality))\n",
        "print(\"Average Closeness Centrality:\", average_centrality(closeness_centrality))\n"
      ],
      "metadata": {
        "id": "fGDnUjHoZmHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **(i) ER Comparision**\n"
      ],
      "metadata": {
        "id": "1PRB7tHld4Mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(G.nodes())                                  # Erdős-Rényi graph\n",
        "m = len(G.edges())\n",
        "p = 2*m / (n*(n-1))                                 # Probability for edge creation\n",
        "G_er = nx.erdos_renyi_graph(n, p)\n"
      ],
      "metadata": {
        "id": "qk3L5_B4ZmKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degree_centrality_er = nx.degree_centrality(G_er)                # Calculate centrality measures for ER graph\n",
        "closeness_centrality_er = nx.closeness_centrality(G_er)\n"
      ],
      "metadata": {
        "id": "X50_sHTJZmN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Erdős-Rényi Graph:\")                                      # Print average centrality measures for ER graph\n",
        "print(\"Average Degree Centrality:\", average_centrality(degree_centrality_er))\n",
        "print(\"Average Closeness Centrality:\", average_centrality(closeness_centrality_er))\n"
      ],
      "metadata": {
        "id": "f3zG016TZmRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **(i) BA  Comparision**\n"
      ],
      "metadata": {
        "id": "bSqOM3HPeRY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G_ba = nx.barabasi_albert_graph(n, int(m/n))                       # Barabási-Albert graph Using m parameter from the original graph\n"
      ],
      "metadata": {
        "id": "eHvN-Ry_ZmUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degree_centrality_ba = nx.degree_centrality(G_ba)                  # Calculate centrality measures for BA graph\n",
        "closeness_centrality_ba = nx.closeness_centrality(G_ba)\n"
      ],
      "metadata": {
        "id": "OGIkXHx8bS3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Barabási-Albert Graph:\")                                                    # Print average centrality measures for BA graph\n",
        "print(\"Average Degree Centrality:\", average_centrality(degree_centrality_ba))\n",
        "print(\"Average Closeness Centrality:\", average_centrality(closeness_centrality_ba))\n"
      ],
      "metadata": {
        "id": "qulCjceTbS6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **(i) WS Comparision**\n"
      ],
      "metadata": {
        "id": "c42UXal1eVcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = int(2*m/n)                                       # Each node is connected to k nearest neighbors in ring topology\n",
        "p_ws = 0.1                                           # Rewiring probability\n",
        "G_ws = nx.watts_strogatz_graph(n, k, p_ws)\n"
      ],
      "metadata": {
        "id": "T8WeEIWwbS-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degree_centrality_ws = nx.degree_centrality(G_ws)         # Calculate centrality measures for WS graph\n",
        "closeness_centrality_ws = nx.closeness_centrality(G_ws)\n"
      ],
      "metadata": {
        "id": "aBYcvsiRbTCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Watts-Strogatz Graph:\")                                                  # Print average centrality measures for WS graph\n",
        "print(\"Average Degree Centrality:\", average_centrality(degree_centrality_ws))\n",
        "print(\"Average Closeness Centrality:\", average_centrality(closeness_centrality_ws))\n"
      ],
      "metadata": {
        "id": "_qHtRfc0bTJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Open Question**\n"
      ],
      "metadata": {
        "id": "q2eHtHjZOT12"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3.1 Our Question based on our dataset analysis**\n",
        "\n",
        "**Question :**  How do shared interests influence the clustering of users within specific geographical locations?.\n"
      ],
      "metadata": {
        "id": "JwhoBsFSOZPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Solution**\n",
        "\n",
        "##### **Step 1 :**  We should Identify subgraphs for users within the same city or country. So below we have perform this using python code and visualize the graph"
      ],
      "metadata": {
        "id": "AdiWxINtkXcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "communities = greedy_modularity_communities(G)                                # Use modularity to find communities\n",
        "print(f\"Number of communities: {len(communities)}\")\n",
        "largest_community = max(communities, key=len)                                 # Optionally, visualize the largest community\n",
        "subgraph = G.subgraph(largest_community)\n",
        "pos = nx.spring_layout(subgraph)\n",
        "nx.draw(subgraph, pos, node_size=10, edge_color=\"lightgreen\", node_color=\"blue\", with_labels=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xjw4l4FlX6OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 2 :**  We should Compute and compare the clustering coefficients and density within these subgraphs. So below we have perform this using python code and did it."
      ],
      "metadata": {
        "id": "r5et3ZeymJ4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "degree_sequence = sorted([d for n, d in G.degree()], reverse=True)                   # Degree distribution plot\n",
        "degree_count = pd.Series(degree_sequence).value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(degree_count.index, degree_count.values)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Number of Nodes')\n",
        "plt.title('Node Degree Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VVKxXNTNx5-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering_coeffs = nx.clustering(G)                                      # Clustering coefficient distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(list(clustering_coeffs.values()))\n",
        "plt.xlabel('Clustering Coefficient')\n",
        "plt.ylabel('Number of Nodes')\n",
        "plt.title('Clustering Coefficient Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NG7xoSbpx6Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Step 3 :**  We should Identify any noticeable patterns in how users with shared interests cluster geographically. So below we have perform this using python code and visualize with connectivity and did it."
      ],
      "metadata": {
        "id": "jQx4ibB7mxJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "partition = community_louvain.best_partition(G)               # Compute the best partition\n",
        "for node, community_id in partition.items():                  # Add community information to nodes\n",
        "    G.nodes[node]['Community'] = community_id\n"
      ],
      "metadata": {
        "id": "VNhRiUAZlj95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "community_id_to_visualize = 0                                       # Visualize a specific community network and Adjust as needed\n",
        "community_nodes = [node for node, data in G.nodes\n",
        " (data=True) if data['Community'] == community_id_to_visualize]     # Extract nodes and edges for the community of interest\n",
        "community_edges = [(u, v) for u, v in G.edges() if u in community_nodes and v in community_nodes]\n",
        "community_graph = nx.Graph()                                        # Create a subgraph for the community\n",
        "community_graph.add_nodes_from(community_nodes)\n",
        "community_graph.add_edges_from(community_edges)\n",
        "plt.figure(figsize=(10, 8))                                           # Draw the community network\n",
        "pos = nx.spring_layout(community_graph)\n",
        "nx.draw(community_graph, pos, with_labels=True, node_color='skyblue', node_size=200, edge_color='gray', linewidths=0.5)\n",
        "plt.title(f'Community {community_id_to_visualize} Network')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u_24Kt4Qx6Ge"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}